{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1950b16-b985-4d4b-82ac-1fc85265a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install icon_registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d5fcb-92bb-4f44-a75f-a5f5fd1d5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_net = icon.FunctionFromVectorField(networks.tallUNet2(dimension=2))\n",
    "\n",
    "for _ in range(3):\n",
    "     inner_net = icon.TwoStepRegistration(\n",
    "         icon.DownsampleRegistration(inner_net, dimension=2),\n",
    "         icon.FunctionFromVectorField(networks.tallUNet2(dimension=2))\n",
    "     )\n",
    "\n",
    "net = net = icon.losses.DiffusionRegularizedNet(inner_net, icon.LNCC(sigma=4), lmbda = 2)\n",
    "net.assign_identity_map(sample_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91d2d6-2232-40e9-8b3e-8c36897d7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GradICON regularizer\n",
    "regularizer = ('Diffusion', icon.losses.DiffusionRegularizedNet(inner_net, icon.LNCC(sigma=4), lmbda = 2))\n",
    "\n",
    "# Initialize list to store vector fields for GradICON regularizer\n",
    "vector_fields = []\n",
    "\n",
    "# Assuming your directory path where you want to save the vector fields and plot outputs\n",
    "output_directory = \"/work/users/a/g/agdylan/icon_registration_project/Diffusion_experiments\"\n",
    "\n",
    " \n",
    "image_A = next(iter(ds))[0].to(device)\n",
    "image_B = next(iter(ds))[0].to(device)\n",
    "\n",
    "\n",
    "# Train 10 registration networks for GradICON regularizer\n",
    "for i in range(10):\n",
    "    # Initialize network\n",
    "    net = regularizer[1]\n",
    "\n",
    "    # Initialize identity map for the provided sample batch\n",
    "    net.assign_identity_map(sample_batch.shape)\n",
    "\n",
    "    # Put network in training mode\n",
    "    net.train()\n",
    "\n",
    "    # Move the network parameters to the specified device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the network using provided dataset for 5 epochs\n",
    "    curves = icon.train_datasets(net, optim, ds, ds, epochs=5)\n",
    "\n",
    "    # Pass both images through the network\n",
    "   \n",
    "\n",
    "    net(image_A, image_B)\n",
    "\n",
    "    # Store vector field tensor\n",
    "    vector_field = net.phi_AB_vectorfield\n",
    "\n",
    "    # Append vector field to list\n",
    "    vector_fields.append(vector_field)\n",
    "\n",
    "    # Plot and save the outputs\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    show(image_A)\n",
    "    plt.title('Image A')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    show(image_B)\n",
    "    plt.title('Image B')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    show(net.warped_image_A)\n",
    "    plt.contour(torchvision.utils.make_grid(net.phi_AB_vectorfield[:2], nrow=3)[0].cpu().detach())  # Draws vertical grid lines\n",
    "    plt.contour(torchvision.utils.make_grid(net.phi_AB_vectorfield[:2], nrow=3)[1].cpu().detach())  # Draws horizontal grid lines\n",
    "    plt.title('Warped Image A with Vector Field')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    show(net.warped_image_A - image_B)\n",
    "    plt.title('Difference Image (Warped A - B)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot output to a file\n",
    "    plot_file_path = os.path.join(output_directory, f\"plot_output_{i + 1}.png\")\n",
    "    plt.savefig(plot_file_path)\n",
    "    print(f\"Plot output {i + 1} saved to: {plot_file_path}\")\n",
    "\n",
    "# Save the entire list of vector fields to a single file\n",
    "full_file_path = os.path.join(output_directory, \"vector_fields.pt\")\n",
    "torch.save(vector_fields, full_file_path)\n",
    "print(f\"All vector fields saved to: {full_file_path}\")\n",
    "\n",
    "# Vector field: represent the spatial transformations needed to align one image with another. Magnitude of each vector represents the amount of displacement\n",
    "# applied to the correspponding pixel \n",
    "\n",
    "# Interpreatation: Each element of the vector field correspond to a specific pixel in the image, indicating how much and which direction the pixel is needed to be transformed\n",
    "\n",
    "# Save images A and B as tensors\n",
    "torch.save(image_A, 'image_A.pt')\n",
    "torch.save(image_B, 'image_B.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87eda3-3935-4d3b-b0a3-7c716160ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of vector fields from the saved file\n",
    "saved_vector_fields = torch.load(\"/work/users/a/g/agdylan/icon_registration_project/Diffusion_experiments/vector_fields.pt\")\n",
    "\n",
    "# Calculate the mean tensor\n",
    "mean_tensor = torch.mean(torch.stack(saved_vector_fields), dim=0)\n",
    "\n",
    "# Calculate the standard deviation tensor\n",
    "std_tensor = torch.std(torch.stack(saved_vector_fields), dim=0)\n",
    "\n",
    "# Now you can use mean_tensor and std_tensor for further analysis or processing\n",
    "print(\"Mean Tensor:\")\n",
    "print(mean_tensor)\n",
    "\n",
    "print(\"\\nStandard Deviation Tensor:\")\n",
    "print(std_tensor)\n",
    "\n",
    "\n",
    "# Mean tensor: each element of the mean tensor represents the average displacement or transformation across the corresponding pixels of the images in the dataset\n",
    "\n",
    "# Standard Deviation Tensor: indicates how much the individual vector fields deviate from the mean tensor at each pixel location. A higher standard deviation implies \n",
    "#greater variability in the alignment pattern across the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27b69e-43d3-468d-87a3-5ae66d4648fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save mean tensor to file\n",
    "mean_file_path = \"/work/users/a/g/agdylan/icon_registration_project/Diffusion_experiments/mean_tensor.pt\"\n",
    "torch.save(mean_tensor, mean_file_path)\n",
    "print(f\"Mean tensor saved to: {mean_file_path}\")\n",
    "\n",
    "# Save standard deviation tensor to file\n",
    "std_file_path = \"/work/users/a/g/agdylan/icon_registration_project/Diffusion_experiments/std_tensor.pt\"\n",
    "torch.save(std_tensor, std_file_path)\n",
    "print(f\"Standard deviation tensor saved to: {std_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8be519-120d-4905-b8d6-d79553b7b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the standard deviation tensor\n",
    "std_tensor = torch.load(\"/work/users/a/g/agdylan/icon_registration_project/Diffusion_experiments/std_tensor.pt\")  # Replace \"/path/to/std_tensor.pt\" with the actual file path\n",
    "\n",
    "std_array = std_tensor.cpu().detach().numpy()\n",
    "\n",
    "# Select a single channel (e.g., channel 0)\n",
    "std_channel = std_array[:, 0]  # Assuming you want to select channel 0\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(std_channel[0], cmap='jet', interpolation='nearest')  # Assuming you want to plot the first image in the batch\n",
    "plt.colorbar(label='Standard Deviation')\n",
    "plt.title('Heatmap of Standard Deviation Tensor')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dfce5a-cd49-4691-aa03-29bfe40b5355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a8bea-4f72-47fc-acee-a08f4c166f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3592cc-339f-46ef-8559-ee4528bdbbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3b4d8-bf81-44d5-be11-e3902586e1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de3141-d075-4cee-9880-8f0ad77c6790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95c94d-2cf2-4714-a128-b6e2d25170f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690605b-b04a-4431-a2b5-a32f437dd5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5549d8a-e1ff-455b-97ff-bcc93b73a2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1983fa-2141-4889-9e9c-d9cf71faf25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a11474-6d23-4bc2-97ae-50eff1c04440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
